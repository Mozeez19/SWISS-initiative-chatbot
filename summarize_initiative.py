import os
import json
from openai import OpenAI
from data.data_fetcher import DataFetcher  # Adjust import if needed

# Create an OpenAI client using the new interface.
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))


def summarize_with_openai(prompt, model="gpt-4o-mini"):
    """
    Use OpenAI's ChatCompletion API (new interface) to generate a summary.

    Args:
        prompt (str): The summarization prompt.
        model (str): The model identifier (default: "gpt-4o-mini").

    Returns:
        str: The summary generated by the model or an error message.
    """
    try:
        completion = client.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7,
            max_tokens=150  # Adjust as needed
        )
        # Use dot notation to access the message content.
        return completion.choices[0].message.content.strip()
    except Exception as e:
        return f"Error summarizing with OpenAI: {e}"


def summarize_initiative(initiative):
    """
    Generate a summary for the given initiative using the OpenAI model.

    Args:
        initiative (dict): Dictionary with initiative details.

    Returns:
        str: A concise summary.
    """
    title = initiative.get("title", "Untitled Initiative")
    full_text = initiative.get("full_text", "")
    if not full_text:
        return "No full text available for summarization."

    # Build metadata from key fields.
    fields = [
        "submitted_on", "preliminary_examination_from", "expiry_of_collection_period",
        "start_of_collection", "voted_on", "entry_into_force", "parliament_decision"
    ]
    metadata_lines = [
        f"{field.replace('_', ' ').title()}: {initiative.get(field, 'N/A')}"
        for field in fields if initiative.get(field)
    ]
    meta_info = f"Title: {title}\n" + "\n".join(metadata_lines)

    # Limit the input text to a manageable size.
    max_text_length = 256  # Adjust as needed
    truncated_text = full_text[:max_text_length]

    prompt = (
        "You are a political assistant. Summarize the following Swiss popular initiative in one concise, clear paragraph. "
        "Include its key objectives and any relevant dates (e.g., submission, vote, or collection period).\n\n"
        f"{meta_info}\n\nExcerpt:\n{truncated_text}"
    )

    return summarize_with_openai(prompt)


def cache_summaries():
    fetcher = DataFetcher()
    initiatives = fetcher.get_all_initiatives()
    summarized_data = []
    for initiative in initiatives:
        title = initiative.get("title", "Untitled Initiative")
        print(f"\nðŸ§  Summarizing: {title}")
        summary = summarize_initiative(initiative)
        initiative["summary"] = summary
        summarized_data.append({
            "title": title,
            "summary": summary
        })
        print(f"ðŸ“„ Summary: {summary}")
    cache_file = "summarized_initiatives.json"
    with open(cache_file, "w", encoding="utf-8") as f:
        json.dump(summarized_data, f, ensure_ascii=False, indent=2)
    print("\nâœ… Summarization complete and cached in 'summarized_initiatives.json'")


if __name__ == "__main__":
    cache_summaries()

###############################################
#MISTRAL CODE BELOW
#########################################


# import subprocess
# import json
# import os
# from data.data_fetcher import DataFetcher  # Adjust import if necessary
#
# def summarize_with_ollama(prompt, model="mistral"):
#     try:
#         result = subprocess.run(
#             ["ollama", "run", model],
#             input=prompt,
#             text=True,
#             capture_output=True,
#             timeout=300
#         )
#         return result.stdout.strip()
#     except subprocess.TimeoutExpired:
#         return "Error summarizing with Ollama: Operation timed out. Please try again with shorter text."
#     except Exception as e:
#         return f"Error summarizing with Ollama: {e}"
#
# def summarize_initiative(initiative):
#     title = initiative.get("title", "Untitled Initiative")
#     full_text = initiative.get("full_text", "")
#     if not full_text:
#         return "No full text available for summarization."
#     # Include additional metadata fields
#     fields = [
#         "submitted_on", "preliminary_examination_from", "expiry_of_collection_period",
#         "start_of_collection", "voted_on", "entry_into_force", "parliament_decision"
#     ]
#     metadata = [f"{field.replace('_', ' ').title()}: {initiative.get(field, 'N/A')}" for field in fields]
#     meta_info = f"Title: {title}\n" + "\n".join(metadata)
#     max_text_length = 256  # Adjust as needed
#     truncated_text = full_text[:max_text_length]
#     prompt = (
#         "You are a political assistant. Summarize the following Swiss popular initiative in a concise, clear paragraph. "
#         "Include key objectives and relevant dates like submission, vote, collection period, and legal status if available.\n\n"
#         f"{meta_info}\n\nExcerpt:\n{truncated_text}"
#     )
#     return summarize_with_ollama(prompt)
#
# def cache_summaries():
#     fetcher = DataFetcher()
#     initiatives = fetcher.get_all_initiatives()
#     summarized_data = []
#     for initiative in initiatives:
#         title = initiative.get("title", "Untitled Initiative")
#         print(f"\nðŸ§  Summarizing: {title}")
#         summary = summarize_initiative(initiative)
#         initiative["summary"] = summary
#         summarized_data.append({
#             "title": title,
#             "summary": summary
#         })
#         print(f"ðŸ“„ Summary: {summary}")
#     cache_file = "summarized_initiatives.json"
#     with open(cache_file, "w", encoding="utf-8") as f:
#         json.dump(summarized_data, f, ensure_ascii=False, indent=2)
#     print("\nâœ… Summarization complete and cached in 'summarized_initiatives.json'")
#
# if __name__ == "__main__":
#     cache_summaries()
